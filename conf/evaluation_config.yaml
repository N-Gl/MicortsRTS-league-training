defaults:
  - default_config

ExperimentConfig:
  evaluate: true
  model_path: 
  evaluation_model_paths: [
                          "league_models/27.11.25_(25 selfplay Agents, 0 Bots)_(finished_PPO_Basis_thesis)/Main_agent_backups/agent_update_2170.pt"
                          ]
  names: [
          "27.11.25_(25 selfplay Agents, 0 Bots)_(finished_PPO_Basis_thesis)_update_2170"
         ]
  exp_name: "bot_27.11.25_(25 selfplay Agents, 0 Bots)_(finished_PPO_Basis_thesis)_update_2170"
  wandb_project_name: new_Evaluation
  prod_mode: true

  seed: 1
  exact_seed: true

  render: true
  render_all: false

  num_eval_episodes: 100
  num_parallel_eval_envs: 25
  num_parallel_selfplay_eval_games: 25        # Number of parallel environments 1 == 2 Selfplay envs
