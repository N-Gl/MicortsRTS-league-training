defaults:
  - default_config

ExperimentConfig:
  evaluate: true
  model_path: 
  evaluation_model_paths: [
                          "league_models/22_12_25__12_12_25__04_12_25__BCagent__league__ent_coef_0_003_exploiter_ent_coef_0_08/Main_agent_backups/agent_update_890.pt",
                          # "models/finished_PPO_Basis_Thesis/finished_PPO_Basis_thesis.pt"
                          ]
  names: [
          "22_12_25__12_12_25__04_12_25__BCagent__league__ent_coef_0_003_exploiter_ent_coef_0_08_update_890",
          # "finished_PPO_Basis_Thesis"
         ]
  exp_name: "22_12_25__12_12_25__04_12_25__BCagent__league__ent_coef_0_003_exploiter_ent_coef_0_08_update_890"
  wandb_project_name: new_Evaluation
  prod_mode: true

  seed:
  exact_seed: true

  render: true
  render_all: false

  num_eval_episodes: 100
  num_parallel_eval_envs: 100
  num_parallel_selfplay_eval_games: 25        # Number of parallel environments 1 == 2 Selfplay envs
