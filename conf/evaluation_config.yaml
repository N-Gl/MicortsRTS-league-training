defaults:
  - default_config

ExperimentConfig:
  evaluate: true
  model_path: 
  evaluation_model_paths: [
                          "league_models/12_12_25__04_12_25__BCagent/Main_agent_backups/agent_update_1710.pt",
                          # "models/finished_PPO_Basis_Thesis/finished_PPO_Basis_thesis.pt"
                          ]
  names: [
          "12_12_25__04_12_25__BCagent",
          # "finished_PPO_Basis_Thesis"
         ]
  exp_name: "12_12_25__04_12_25__BCagent_vs_worse_models"
  wandb_project_name: new_Evaluation
  prod_mode: true

  seed:
  exact_seed: true

  render: false
  render_all: false

  num_eval_episodes: 100
  num_parallel_eval_envs: 100
  num_parallel_selfplay_eval_games: 25        # Number of parallel environments 1 == 2 Selfplay envs
